# About This Project
This project demonstrates a complete data pipeline, starting from data extraction to comparative analysis in Python and SQL.

# Workflow Overview:
1️⃣ Data Acquisition – Downloading a dataset from Kaggle using the Kaggle API.  

2️⃣ Data Processing & Cleaning – Loading the dataset into Python, performing data preprocessing using Pandas, handling missing values, and ensuring data consistency.


3️⃣ Data Transfer to SQL Server – Storing the cleaned and processed data into a SQL Server database.

4️⃣ SQL Analysis – Performing similar analyses in SQL to compare with Python-based results.

5️⃣ Comparing Python & SQL Queries – Understanding how Python and SQL handle data transformations and optimizations differently.

# Tech Stack Used:
- Python (Pandas, NumPy, Matplotlib, Seaborn)
- SQL Server (Data Storage & Queries)
- Kaggle API (Dataset Download)
# Key Learnings & Insights:
--> How to efficiently download and manage datasets using the Kaggle API.

--> Best practices for data cleaning and transformation in Python.

--> How to store and retrieve data from SQL Server.

--> Understanding performance differences between Python and SQL queries.
